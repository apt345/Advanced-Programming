{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting wind energy production with Machine Learning\n",
    "\n",
    "Arturo Prieto Tirado and Pere Fuster Escriv√†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the teacher: \n",
    "\n",
    "- This work follows the structure of the task. \n",
    "\n",
    "- Any coment with regards to the results is displayed at the end, section Conclusions and Insight: Performance evaluation and Attribute selection. \n",
    "\n",
    "- In total, there are 9 models built (2 knn + 2 trees + 2 svm + 3knn) the 2n knn model in the 2nd part is very similar to the first Knn in the 3rd task. \n",
    "\n",
    "\n",
    "Table of contents: \n",
    "\n",
    "Task 1: \n",
    "\n",
    "- KNN + KNN with hyperparameter tuning \n",
    "- Reg Trees + RT with hyperparameter tuning \n",
    "- SVM + SVM with hyperparameter tuning \n",
    "\n",
    "Task 2: \n",
    "\n",
    "- Feature selection with KNN \n",
    "\n",
    "Conclusions \n",
    "\n",
    "\n",
    "References: \n",
    "- Slides + Recordings \n",
    "- https://scikit-learn.org/stable/\n",
    "- Introduction to ML in Python (Book) \n",
    "- Stackoverflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split # \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import tree\n",
    "\n",
    "# Please change the directory to where the data is stored\n",
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"C:\\\\Users\\\\arpri\\\\OneDrive\\\\Escritorio\\\\libros\\\\master\\\\Segundo Semicuatrimestre\\\\ProgramacionAvanzada\\\\Proyecto 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f345b1feccaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "a = (1,2,3)\n",
    "\n",
    "b = a\n",
    "\n",
    "b[0]=10\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "\n",
    "The very first step is to load the dataset, delete month, steps, day and hour and insert  5% of total observations as NA in 10% of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "energy       0.000000\n",
       "year         0.000000\n",
       "p54.162.1    0.000000\n",
       "p54.162.2    0.050025\n",
       "p54.162.3    0.000000\n",
       "               ...   \n",
       "v100.21      0.000000\n",
       "v100.22      0.000000\n",
       "v100.23      0.000000\n",
       "v100.24      0.050025\n",
       "v100.25      0.000000\n",
       "Length: 552, dtype: float64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "my_NIA = 100441384 # NIA Pere Fuster \n",
    "np.random.seed(my_NIA)\n",
    "\n",
    "data = pd.read_pickle('wind_pickle.pickle')\n",
    "data = data.drop(['month','steps','day','hour'], axis=1)\n",
    "\n",
    "grey = data.drop(['year','energy'], axis=1)\n",
    "grey = grey.sample(frac = 0.10, axis = 'columns')\n",
    "\n",
    "data.shape\n",
    "grey.shape\n",
    "\n",
    "for col in grey.columns:\n",
    "    grey.loc[grey.sample(frac = 0.05).index, col] = np.nan\n",
    "\n",
    "grey.isna().sum()/grey.shape[0] # checking\n",
    "\n",
    "data[grey.columns] = grey\n",
    "\n",
    "data.isna().sum()/data.shape[0] # double-checking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create the training, validation and testing datasets in chronological order. We create also a dataframe \"train\" containing both training and validation that will be used for simple models with no hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.year.min() # checking years ranges \n",
    "data.year.max()\n",
    "\n",
    "#Train partition: data belonging to 2005 and 2006.\n",
    "# Validation partition (inner): 2007 and 2008 data.\n",
    "# Test partition (outer): 2009 and 2010.\n",
    "train=data[(data['year'] < 2009)]\n",
    "train_train = data[(data['year'] < 2007)]\n",
    "train_validation = data[(data['year'] >= 2007) & (data['year'] < 2009)]\n",
    "holdout = data[(data['year'] >= 2009) & (data['year'] < 2010)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, remove column year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['year'], axis = 1)\n",
    "train_train = train_train.drop(['year'], axis = 1)\n",
    "train_validation = train_validation.drop(['year'], axis = 1)\n",
    "holdout = holdout.drop(['year'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Model selection and Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code belows includes all the steps related to data partition, which will be necessary to evaluate the models and to be able to improve their performance with parameter tuning. \n",
    "First, we remove the response, energy, from the training and testing set and store it as a response y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['energy'], axis=1)\n",
    "y_train = train.energy\n",
    "X_test = holdout.drop(['energy'], axis=1)\n",
    "y_test = holdout.energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert the data to numpy matrices, although scitkit learn can deal with our pandas dataframes since all the data are numerical variables (no strings inside)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.to_numpy()\n",
    "train_train = train_train.to_numpy()\n",
    "train_validation=train_validation.to_numpy()\n",
    "holdout=holdout.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define a train validation grid search to distinguish between proper training and validation for hyper-parameter tuned models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a fixed train/validation grid-search\n",
    "# -1 means training, 0 means validation\n",
    "validation_indices = np.zeros(X_train.shape[0])\n",
    "a = np.linspace(0, (train_train.shape[0] - 1), train_train.shape[0])*0\n",
    "v_indices = np.linspace(0, (train_validation.shape[0] - 1), train_validation.shape[0])+1\n",
    "b = (v_indices/v_indices)*(-1)\n",
    "\n",
    "validation_indices = np.concatenate((a, b), axis=0)\n",
    "tr_val_partition = PredefinedSplit(validation_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And create a dataframe to store the Mean Absolute Error of the different models for later comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store the MAE of all the models\n",
    "MAE = pd.DataFrame({'model': range(1,10), 'MAE': range(11,20)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN & SVM \n",
    "\n",
    "Since KNN and SVM need the same preprocessing, They belong to the same section \n",
    "\n",
    "Let's start with KNN with default hyperparameters. We will build a pipeline that applies standarisation, imputes the missing values and does feature selection with classificator, the KNN (All with the default parameters).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardisation needed for KNN\n",
    "MinMax = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "# Replace NAs \n",
    "imputer = sklearn.impute.SimpleImputer()\n",
    "\n",
    "# Feature selection \n",
    "selector = sklearn.feature_selection.SelectKBest()\n",
    "\n",
    "# Classificator \n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# Building the pipeline \n",
    "reg = Pipeline([\n",
    "('minmax', MinMax), \n",
    "('impute', imputer),\n",
    "('select', selector),\n",
    "('knn_regression', knn)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the pipeline, we can use the fit() function on it with the training dataset and the response and afterwards make a prediction with the predict() function on the testing dataset and compare with the original results in the testing set with MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374.9177654723127\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions for the trainning and testing sets \n",
    "y_test_pred = reg.predict(X_test)\n",
    "\n",
    "#saving the MAE for future comparisons\n",
    "MAE.iloc[0,1] = metrics.mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Printing MAE of training and testing\n",
    "print(MAE.iloc[0,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we get a Mean Absolute Error of when evaluated on the testing set, which doesn't say much on itself, but it is useful to make comparisons between models.\n",
    "\n",
    "Next step is using KNN with hyperparameter tuning. We introduce the pipeline in the same way as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "### KNN and SVM PIPELINE \n",
    "\n",
    "# Standardisation \n",
    "MinMax = sklearn.preprocessing.MinMaxScaler() # SVMs assume that the data it works with is in a standard range\n",
    "\n",
    "# NAs Action \n",
    "imputer = sklearn.impute.SimpleImputer()\n",
    "\n",
    "# Feature selection \n",
    "selector = sklearn.feature_selection.SelectKBest() # Select the most important 3 \n",
    "\n",
    "# Classificator \n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# Building the pipeline \n",
    "reg = Pipeline([\n",
    "('minmax', MinMax), \n",
    "('impute', imputer),\n",
    "('select', selector),\n",
    "('knn_regression', knn)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now we add hyper-parameter search space so that it can impute the NA using the median or the mean; work with 1 up to 12 neighbors with uniform or weighted distance. This way, the algorithm will find the best choice for all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hyper-parameter (search) space\n",
    "param_grid = {\n",
    "'select__k':  range(1,30),\n",
    "'impute__strategy': ['mean', 'median'],\n",
    "'knn_regression__n_neighbors': range(1,12),\n",
    "'knn_regression__weights': ['uniform', 'distance']\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to specify the search method for the cross validation grid that will be used in the hyperparameter tuning. In contrast to GridSearchCV, not all parameter values are tried out. Instead, a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter (The default is set at 10, but we will change it to 4 for the sake of the exercise, since for this case we'd go for GridSearch without randomising).\n",
    "\n",
    "We use the negative mean absolute error and the validation partition. Also, n_jobs allows us to work in parallel to be faster. Since our computers have 8 cores, we will use 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Search Method, evaluation method and performance measure\n",
    "reg_grid = RandomizedSearchCV(reg, param_grid, scoring = 'neg_mean_absolute_error', n_iter = 4, \n",
    "                              cv = tr_val_partition, n_jobs = 7, verbose = 1, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally fit our model using the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 4 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done   4 out of   4 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([ 0,  0, ..., -1, -1])),\n",
       "                   estimator=Pipeline(steps=[('minmax', MinMaxScaler()),\n",
       "                                             ('impute', SimpleImputer()),\n",
       "                                             ('select', SelectKBest()),\n",
       "                                             ('knn_regression',\n",
       "                                              KNeighborsRegressor())]),\n",
       "                   n_iter=4, n_jobs=7,\n",
       "                   param_distributions={'impute__strategy': ['mean', 'median'],\n",
       "                                        'knn_regression__n_neighbors': range(1, 12),\n",
       "                                        'knn_regression__weights': ['uniform',\n",
       "                                                                    'distance'],\n",
       "                                        'select__k': range(1, 30)},\n",
       "                   random_state=0, scoring='neg_mean_absolute_error',\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model\n",
    "reg_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And make predictions using predict() on the testing dataset, so that we can compare with the original testing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'select__k': 28, 'knn_regression__weights': 'distance', 'knn_regression__n_neighbors': 10, 'impute__strategy': 'median'}\n",
      "344.4816562010301\n",
      "341.2523064928945\n"
     ]
    }
   ],
   "source": [
    "# Making prediction predictions for the training and testing sets \n",
    "y_test_pred = reg_grid.predict(X_test) \n",
    "\n",
    "print(reg_grid.best_params_) # Best parameters identified with Randomised Search \n",
    "\n",
    "print(- reg_grid.best_score_) # Best MAE in the validation set  \n",
    "\n",
    "MAE.iloc[1,1] = metrics.mean_absolute_error(y_test, y_test_pred)\n",
    "print(MAE.iloc[1,1]) # Testing MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal hyperparameters are 28 features, distance weights, 10 neighbors and median imputation. The new MAE of the model in the testing dataset is 341, which has improved with respected to the non-tuned model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "\n",
    "The goal of an SVM is to create a flat boundary, called hyperplane, which leads to fairly homogeneous partitions of data on either side.\n",
    "\n",
    "Therefore these are the hyperameters of these applications: \n",
    "\n",
    "- C is the penalty parameter, it models the importance of missclasification\n",
    "- Kernel is the kernel function used to map the data to a higher dimension space\n",
    "- epsilon is the margin of tolerance where to penalty is given to errors\n",
    "\n",
    "Once the dimension have been increased to allow for a flat linear separation.\n",
    "\n",
    "First we do SVM with default hyperparamters. We define the pipeline that scales, imputes NA and does feature selection with default hyperparameters analogously as we did for KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardisation \n",
    "MinMax = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "# NAs Action \n",
    "imputer = sklearn.impute.SimpleImputer()\n",
    "\n",
    "# Feature selection \n",
    "selector = sklearn.feature_selection.SelectKBest() # Select the most important 3 \n",
    "\n",
    "# Classificator \n",
    "svm = SVR()\n",
    "\n",
    "# Building the pipeline \n",
    "reg = Pipeline([\n",
    "('minmax', MinMax), \n",
    "('impute', imputer),\n",
    "('select', selector),\n",
    "('supportVM', svm)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we proceed to fit the model using the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('minmax', MinMaxScaler()), ('impute', SimpleImputer()),\n",
       "                ('select', SelectKBest()), ('supportVM', SVR())])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, predict and check its negative MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410.538098715742\n"
     ]
    }
   ],
   "source": [
    "# Making prediction predictions for the trainning and testing sets \n",
    "y_test_pred = reg.predict(X_test)\n",
    "\n",
    "# Printing MAE\n",
    "MAE.iloc[2,1] = metrics.mean_absolute_error(y_test, y_test_pred)\n",
    "print(MAE.iloc[2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a MAE of 410, let's now use SVM with hyperparameter tuning and compare.\n",
    "The pipeline is done in the same way as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardisation \n",
    "MinMax = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "# NAs Action \n",
    "imputer = sklearn.impute.SimpleImputer()\n",
    "\n",
    "# Feature selection \n",
    "selector = sklearn.feature_selection.SelectKBest() # Select the most important 3 \n",
    "\n",
    "# Classificator \n",
    "svm = SVR()\n",
    "\n",
    "# Building the pipeline \n",
    "reg = Pipeline([\n",
    "('minmax', MinMax), \n",
    "('impute', imputer),\n",
    "('select', selector),\n",
    "('supportVM', svm)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to define the hyper-parameter space where to search. The hyperparameters are the way to replace NAs: mean or median; the penalty parameter; the type of kernel function: linear, polynomical, radial basis function (rfb) or a sigmoid and the epsilon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "'select__k':  range(1,30),\n",
    "'impute__strategy': ['mean', 'median'],\n",
    "'supportVM__C': list(np.linspace(0.1, 50, 500)),\n",
    "'supportVM__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "'supportVM__epsilon': list(np.linspace(0.001, 1, 1000))\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to specify the search method for the cross validation grid that will be used in the hyperparameter tuning. We use randomized search for faster results with the negative mean absolute error and the validation partition in parallel as done for KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Search Method, evaluation method and performance measure\n",
    "reg_grid = RandomizedSearchCV(reg, param_grid, scoring = 'neg_mean_absolute_error', cv = tr_val_partition, n_iter = 10, n_jobs = 6, verbose=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "reg_grid = reg_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's make predictions with the testing dataset and analyze the power of the model with the MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supportVM__kernel': 'rbf', 'supportVM__epsilon': 0.47900000000000004, 'supportVM__C': 28.099999999999998, 'select__k': 27, 'impute__strategy': 'mean'}\n",
      "341.43716663495667\n",
      "341.5112901824232\n"
     ]
    }
   ],
   "source": [
    "# The tuned method can be used for making predictions, just as any fit machine learning method\n",
    "y_test_pred = reg_grid.predict(X_test)\n",
    "\n",
    "MAE.iloc[3,1] = metrics.mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(reg_grid.best_params_) # Best parameters identified with Randomised Search \n",
    "print(- reg_grid.best_score_) # Trainning MAE\n",
    "print(MAE.iloc[3,1]) # Testing MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a MAE of 341, way better than the SVM with default hyperparameters. The optimal hyperparameters for SVM turned out to be a radial basis function, an epsilon of 0.47900000000000004, a penalty of 28.0999..., 27 neighbors and mean value imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Trees\n",
    "\n",
    "The last model we will work with are regression trees. These models don't need scaling, so we define a simpler pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NA imputation\n",
    "imputer = sklearn.impute.SimpleImputer()\n",
    "\n",
    "# Feature selection \n",
    "selector = sklearn.feature_selection.SelectKBest() # Select the most important \n",
    "\n",
    "# Classificator \n",
    "arbol = tree.DecisionTreeRegressor()\n",
    "\n",
    "# Building the pipeline (Worth putting the imputer before the selector transformer)\n",
    "reg = Pipeline([\n",
    "('impute', imputer),\n",
    "('select', selector),\n",
    "('decisiontree', arbol)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit the model using the training dataset and predict using the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469.2032030401738\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Making prediction predictions for the testing sets\n",
    "y_test_pred = reg.predict(X_test)\n",
    "\n",
    "MAE.iloc[4,1] = metrics.mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Printing Testing MAE\n",
    "print(MAE.iloc[4,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a MAE of 469. Now let's work with hyperparameter tuning. Define the same pipeline: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NA imputation\n",
    "imputer = sklearn.impute.SimpleImputer()\n",
    "\n",
    "# Feature selection \n",
    "selector = sklearn.feature_selection.SelectKBest() # Select the most important \n",
    "\n",
    "# Classificator \n",
    "trees = tree.DecisionTreeRegressor()\n",
    "\n",
    "# Building the pipeline \n",
    "reg = Pipeline([\n",
    "('impute', imputer),\n",
    "('select', selector),\n",
    "('decisiontree', trees)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the hyperparamater grid to search. We can modify the criterion of the tree, its depth and the number of leaves, as well as the imputation method or the number of neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "'impute__strategy': ['mean', 'median'],\n",
    "'select__k':  range(1,30),\n",
    "'decisiontree__criterion': [\"mse\", \"friedman_mse\", \"mae\", \"poisson\"], # Default = Gini.\n",
    "'decisiontree__max_depth': list(np.linspace(2, 10, 9)), # The maximum depth of the tree.\n",
    "'decisiontree__min_samples_split': list(np.linspace(2, 11, 10).astype(int)) # The minimum number of samples required to split an internal node\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to specify the search method for the cross validation grid that will be used in the hyperparameter tuning. We use randomized search for faster results with the negative mean absolute error and the validation partition in parallel as done before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Search Method, evaluation method and performance measure\n",
    "reg_grid = RandomizedSearchCV(reg, param_grid, scoring = 'neg_mean_absolute_error', n_iter = 8, \n",
    "                              cv = tr_val_partition, n_jobs = 6, verbose = 1, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally fit the model using the training set and compare resuls with the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 8 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   8 | elapsed:    0.6s remaining:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done   8 out of   8 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'select__k': 16, 'impute__strategy': 'mean', 'decisiontree__min_samples_split': 8, 'decisiontree__max_depth': 6.0, 'decisiontree__criterion': 'mae'}\n",
      "362.2832950949367\n",
      "366.14766015200865\n"
     ]
    }
   ],
   "source": [
    "reg_grid = reg_grid.fit(X_train, y_train)\n",
    "\n",
    "# The tuned method can be used for making predictions, just as any fit machine learning method\n",
    "y_test_pred = reg_grid.predict(X_test)\n",
    "\n",
    "MAE.iloc[5,1] = metrics.mean_absolute_error(y_test, y_test_pred)  \n",
    "\n",
    "print(reg_grid.best_params_) # Best parameters identified with Randomised Search \n",
    "print(- reg_grid.best_score_) # Trainning MAE\n",
    "print(MAE.iloc[5,1]) # Testing MAEreg_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A MAE of 366 is obtained on the testing set which is significantly better than 469 obtained with no tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the optimal MAE is 341, with a tie between both tuned KNN and SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atribute selection using KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout all this section, the impute strategy median and the weighted distance will be used for knn, since they were the best approaches found in the previous section. First, we will only use feature selection. Let's define the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardisation \n",
    "MinMax = sklearn.preprocessing.MinMaxScaler() # SVMs assume that the data it works with is in a standard range\n",
    "\n",
    "# NAs Action \n",
    "imputer = sklearn.impute.SimpleImputer(strategy = 'median')\n",
    "\n",
    "# Feature selection \n",
    "selector = sklearn.feature_selection.SelectKBest() # Select the most important 3 \n",
    "\n",
    "# Classificator \n",
    "knn = KNeighborsRegressor(weights='distance')\n",
    "\n",
    "# Building the pipeline \n",
    "reg = Pipeline([\n",
    "('minmax', MinMax), \n",
    "('impute', imputer),\n",
    "('select', selector),\n",
    "('knn_regression', knn)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the hyperparameter search space to tune. In this case, the number of features to select (from 1 atribute to 550 in total) and the number of neighbours for knn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hyper-parameter (serach) space\n",
    "param_grid = {\n",
    "'select__k':  range(1,550),\n",
    "'knn_regression__n_neighbors': range(1,12) \n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we proceed define the hyperparamter tuning method, which is again randomized search cross validation faster in this case with very large range of k (1:550) but with more iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Search Method, evaluation method and performance measure\n",
    "fs1 = RandomizedSearchCV(reg, param_grid, scoring = 'neg_mean_absolute_error', n_iter = 50, \n",
    "                              cv = tr_val_partition, n_jobs = 7, verbose = 1, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we fit the model, predict and check its score and its result on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 50 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=7)]: Done  50 out of  50 | elapsed:   18.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'select__k': 132, 'knn_regression__n_neighbors': 10}\n",
      "300.3642248680189\n"
     ]
    }
   ],
   "source": [
    "fs1 = fs1.fit(X_train, y_train)\n",
    "\n",
    "# The tuned method can be used for making predictions, just as any fit machine learning method\n",
    "y_test_pred = fs1.predict(X_test)\n",
    "MAE.iloc[6,1] = metrics.mean_absolute_error(y_test, y_test_pred)\n",
    "print(fs1.best_params_)\n",
    "print(MAE.iloc[6,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the optimal values are 132 features with 10 neighbors, leading to a MAE of 300 when evaluated on the testing set. We will look at the features selected by this model afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to fit a knn with PCA selection. Again, we define the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardisation \n",
    "MinMax = sklearn.preprocessing.MinMaxScaler() # SVMs assume that the data it works with is in a standard range\n",
    "\n",
    "# NAs Action \n",
    "imputer = sklearn.impute.SimpleImputer(strategy='median')\n",
    "\n",
    "# Classificator \n",
    "knn = KNeighborsRegressor(weights='distance')\n",
    "\n",
    "# Attribute tranformation with PCA \n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "\n",
    "# Building the pipeline \n",
    "reg = Pipeline([\n",
    "('minmax', MinMax), \n",
    "('impute', imputer),\n",
    "(\"pca\", pca), \n",
    "('knn_regression', knn)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter search space for 1 to 12 neighbors and 1 to 6 PC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Defining hyper-parameter (serach) space\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "param_grid = {\n",
    "'pca__n_components':  range(1,6),\n",
    "'knn_regression__n_neighbors': range(1,12)\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the cross validation with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Search Method, evaluation method and performance measure\n",
    "fs2 = GridSearchCV(reg, param_grid, scoring='neg_mean_absolute_error', cv=tr_val_partition , n_jobs=7, verbose=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we fit the model and check its optimal hyperparameters as well as making predictions and checking its score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 55 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=7)]: Done  55 out of  55 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn_regression__n_neighbors': 10, 'pca__n_components': 5}\n",
      "342.71773838653195\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "fs2 = fs2.fit(X_train, y_train)\n",
    "\n",
    "# The tuned method can be used for making predictions\n",
    "y_test_pred = fs2.predict(X_test)\n",
    "\n",
    "\n",
    "#check scores in training\n",
    "print(fs2.best_params_)\n",
    "\n",
    "#check scores in testing\n",
    "MAE.iloc[7,1] = metrics.mean_absolute_error(y_test, y_test_pred)\n",
    "print(MAE.iloc[7,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal model is one with 10 neighbors and 5 PC that has a MAE of 343 when evaluated on the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we perform both feature selection and PCA. To reduce computational costs, we reduce the hyperparameter space search to values close to those of the solutions above. First we define the pipeline combining the feature selection and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardisation \n",
    "MinMax = sklearn.preprocessing.MinMaxScaler() # SVMs assume that the data it works with is in a standard range\n",
    "\n",
    "# NAs Action \n",
    "imputer = sklearn.impute.SimpleImputer(strategy='median')\n",
    "\n",
    "# Feature selection \n",
    "selector = sklearn.feature_selection.SelectKBest() # Select the most important 3 \n",
    "# Classificator \n",
    "knn = KNeighborsRegressor(weights='distance')\n",
    "\n",
    "# Attribute tranformation with PCA \n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "\n",
    "# Feature Union \n",
    "combined_features = FeatureUnion([(\"pca\", pca),\n",
    "(\"select\", selector)])\n",
    "\n",
    "# Building the pipeline \n",
    "reg = Pipeline([\n",
    "('minmax', MinMax), \n",
    "('impute', imputer),\n",
    "(\"features\", combined_features), \n",
    "('knn_regression', knn)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the hyperparameter search space which includes number of neighbours, number of PCA components and number of features selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hyper-parameter (serach) space\n",
    "\n",
    "param_grid = {\n",
    "'features__select__k':  range(100,180),\n",
    "'features__pca__n_components':  range(1,6),\n",
    "'knn_regression__n_neighbors': range(6,12)\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the cross validation grid, this time using grid search to check all the options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Search Method, evaluation method and performance measure\n",
    "\n",
    "reg_grid = GridSearchCV(reg, param_grid, scoring = 'neg_mean_absolute_error', cv = tr_val_partition , n_jobs = 7, verbose = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally fit the model on the traning set and check the predictions on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 2400 candidates, totalling 2400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=7)]: Done 1236 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=7)]: Done 1786 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=7)]: Done 2400 out of 2400 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'features__pca__n_components': 1, 'features__select__k': 179, 'knn_regression__n_neighbors': 10}\n",
      "322.42267193681016\n"
     ]
    }
   ],
   "source": [
    "reg_grid = reg_grid.fit(X_train, y_train)\n",
    "\n",
    "# The tuned method can be used for making predictions, just as any fit machine learning method\n",
    "y_test_pred = reg_grid.predict(X_test)\n",
    "\n",
    "print(reg_grid.best_params_)\n",
    "\n",
    "#check scores in testing\n",
    "MAE.iloc[8,1] = metrics.mean_absolute_error(y_test, y_test_pred)\n",
    "print(MAE.iloc[8,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a MAE of 322 on the testing set, which is actually worse than knn with just feature selection but better than knn with just PCA. Also, knn with feature selection (MAE=300) is the best model of all, better than SVM and KNN from previous section that had MAE=341."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion and Conclusions\n",
    "\n",
    "\n",
    "## Performance \n",
    "\n",
    "The best model turned out to be knn with feature selection with 132 features and 10 neighbors, with a MAE of 300. The performance of the models in order of appearance in the project is summarized in the following plot where we can see the winner knn followed by the mixed PCA and KNN from section 3 and tuned SVM and KNN from section 1 both tied with KNN with PCA from section 3. Finally, trees turned out to be the worst models of all, followed by default KNN, SVM and trees, in that order.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot( 'model', 'MAE', data=MAE, linestyle='-', marker='o', color = 'Black')\n",
    "\n",
    "# Custom Axis title\n",
    "plt.title(\"Performance Evaluation\", loc = 'left')\n",
    "plt.xlabel('Models used (By Application order)', color = 'Black', fontsize='12', horizontalalignment='center')\n",
    "plt.ylabel('MAE on the testing set', color = 'Black', fontsize='12', horizontalalignment='center')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insight\n",
    "\n",
    "The importance is not as simple as seeing the features selected. Features are potentially correlated between each other, meaning they contain overlapping information. This unfolds so that a model with a variable A, adding B might be more relevant that adding C, but if D is correlated with B and was also in the initial model with A, then it would be more relevant to add C. This is often called colineality (although in ML/Non-parametric modelling we do not care about whether the inter-relation is linear), and is something that can't be overlooked in many contextes. \n",
    "\n",
    "This does not mean looking at the frequency of selection of some variables used is no longer valid. In this particular case, we might be facing a sitatuation that because some wind farms conditions are very related, models tend to select a section of them to make predictions. \n",
    "\n",
    "We have particularly found out that only 5 different attributes out of the 22 total are considered important: p59.162 (surface pressure), , u10n (10 metre U wind component), iews (Instantaneous eastward turbulent surface stress), inss (Instantaneous northward turbulent surface) and u100 (100 metre U wind component) and for very particular locations, positions 24 and 25: cape (Convective available potential energy), lai_hv (Leaf area index, high vegetation), flsr (Forecast logarithm of surface roughness for heat), stl1(Soil temperature level 1). Probably this is due to the fact that these two places present special characteristics compared to the others, in particular, in these 4 variables. The physical interpretation of how these or any variable might contribute to energy generation is, however, beyond our reach since we are not technical experts on the matter.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cape.24', 'cape.25', 'p59.162.1', 'p59.162.2', 'p59.162.3',\n",
       "       'p59.162.4', 'p59.162.5', 'p59.162.6', 'p59.162.7', 'p59.162.8',\n",
       "       'p59.162.9', 'p59.162.10', 'p59.162.11', 'p59.162.12', 'p59.162.13',\n",
       "       'p59.162.14', 'p59.162.15', 'p59.162.16', 'p59.162.17', 'p59.162.18',\n",
       "       'p59.162.19', 'p59.162.20', 'p59.162.21', 'p59.162.22', 'p59.162.23',\n",
       "       'lai_hv.24', 'lai_hv.25', 'u10n.1', 'u10n.4', 'u10n.5', 'u10n.6',\n",
       "       'u10n.9', 'u10n.10', 'u10n.11', 'u10n.14', 'u10n.15', 'u10n.19',\n",
       "       'u10n.20', 'u10n.21', 'stl1.24', 'u10.1', 'u10.4', 'u10.5', 'u10.6',\n",
       "       'u10.7', 'u10.8', 'u10.9', 'u10.10', 'u10.11', 'u10.12', 'u10.14',\n",
       "       'u10.15', 'u10.16', 'u10.19', 'u10.20', 'u10.21', 'u10.22', 'stl3.24',\n",
       "       'stl3.25', 'iews.1', 'iews.2', 'iews.3', 'iews.4', 'iews.5', 'iews.6',\n",
       "       'iews.7', 'iews.8', 'iews.9', 'iews.10', 'iews.11', 'iews.12',\n",
       "       'iews.13', 'iews.14', 'iews.15', 'iews.16', 'iews.17', 'iews.18',\n",
       "       'iews.19', 'iews.20', 'iews.21', 'iews.22', 'iews.23', 'iews.24',\n",
       "       'iews.25', 'inss.1', 'inss.2', 'inss.3', 'inss.4', 'inss.5', 'inss.6',\n",
       "       'inss.7', 'inss.8', 'inss.9', 'inss.10', 'inss.11', 'inss.12',\n",
       "       'inss.13', 'inss.14', 'inss.15', 'inss.16'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_model_s1[0:100] # First 100 items in the features object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['inss.17', 'inss.18', 'inss.19', 'inss.20', 'inss.21', 'inss.22',\n",
       "       'inss.23', 'flsr.24', 'flsr.25', 'u100.1', 'u100.2', 'u100.3', 'u100.4',\n",
       "       'u100.5', 'u100.6', 'u100.7', 'u100.8', 'u100.9', 'u100.10', 'u100.11',\n",
       "       'u100.12', 'u100.13', 'u100.14', 'u100.15', 'u100.16', 'u100.17',\n",
       "       'u100.18', 'u100.19', 'u100.20', 'u100.21', 'u100.22', 'u100.23'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_model_s1[100:132] # Rest of the items in the features object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the following code extracts the importance of each location by counting how many variables at that location contribute to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part runs the First model of the second section with the optimal parameters, so that it's possible \n",
    "# to access all the names of the features selected. \n",
    "\n",
    "# This is based on the best parameters in the first model (Of this, the last, section)\n",
    "selector = sklearn.feature_selection.SelectKBest(k = 132) \n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors = 10,\n",
    "                         weights = 'distance')\n",
    "reg = Pipeline([\n",
    "('minmax', MinMax), \n",
    "('impute', imputer),\n",
    "('select', selector),\n",
    "('knn_regression', knn)])\n",
    "\n",
    "fs11 = reg.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = fs11.predict(X_test)\n",
    "\n",
    "features_model_s1 = data.iloc[:,\n",
    "                            reg[\"select\"].get_support(indices = True)].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = features_model_s1.shape[0]\n",
    "names = range(0,26)\n",
    "farm = np.linspace(0, 24, 25) * 0\n",
    "for i in range(0,rep): \n",
    "    a = str(features_model_s1[i]) + \"end_check\"\n",
    "    for j in range(0, 26):\n",
    "        farm[j-1] = str.count(a, \".\" + str(names[j]) + \"end_check\") + farm[j-1]\n",
    "#farm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pos = np.arange(25) + 1\n",
    "x = np.array(farm)\n",
    "plt.bar(y_pos, x, color = 'grey')\n",
    "\n",
    "plt.title(\"Frequency of the farms used in the model\", loc = 'left')\n",
    "plt.xlabel('Farm by name', color = 'Black', fontsize = '12', horizontalalignment = 'center')\n",
    "plt.ylabel('Count', color = 'Black', fontsize = '12', horizontalalignment = 'center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all the farms contribute more or less equally. In fact, Sotavento (number 13) only contributes with 4 variables, tied in the least contributors with some other locations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
